---
title: "STAT429_Project_Proposal"
output:
  pdf_document: default
  html_document: default
linkcolor: blue
date: "2025-03-26"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(out.width="70%", fig.align='center')
```

# Team Members

Jaehyung Kim – GR, netid: jk38\
Karina Grewal – GR, netid: kgrewal2\
Steve Liang - GR, netid: stevel3

# Data Description

The data signifies power consumption in Tetouan, Morocco, recorded from January 1st, 2017 to December 30th, 2017. This is collected from [Amendis](https://www.amendis.ma/fr), the electricity distributor in that region, and we have obtained this dataset from [Kaggle](https://www.kaggle.com/datasets/fedesoriano/electric-power-consumption/data). In terms of the regressor variables, there are five features, which are “temperature”, “humidity”, “wind speed”, “General Diffuse Flows”, “Diffuse Flows”, and three response variables “Zone 1 Power Consumption”, “Zone 2 Power Consumption”, and “Zone 3 Power Consumption” measurements.

To analyze the effects of the weather factors on power consumption, we decided to remove “General Diffuse Flows” as that variable counts for radiation that bounces off of nearby surfaces.

Feature Variables:

-   Temperature: Measured in Celsius (°C)\
-   Humidity: Weather humidity\
-   Wind Speed: Wind speed\
-   Diffuse Flows: Represents amount of diffused solar radiation

Response Variables:

-   Zone 1 Power Consumption: Power Consumption in Quads zone (kV)\
-   Zone 2 Power Consumption: Power Consumption in Smir zone (kV)\
-   Zone 3 Power Consumption: Power Consumption in Boussafou zone (kV)

These feature variables were measured in 10-minute intervals throughout the day. Lastly, we aggregated zones 1, 2, and 3 to analyze the comprehensive power consumption in Tetouan. This integrated variable will be used as the outcome to demonstrate the various effects of the regressor variables.

# Preliminary Data Analysis and Visualization

```{r, include=FALSE}
library(tidyverse)
library(astsa)
library(ggplot2)
library(ggcorrplot)
```

```{r, include=FALSE}
powerconsumption <- read_csv("powerconsumption.csv", 
    col_types = cols(Datetime = col_datetime(format = "%m/%d/%Y %H:%M")))
powerconsumption <- powerconsumption %>% 
  select(-c(GeneralDiffuseFlows)) %>%
  mutate(total_consumption = PowerConsumption_Zone1 + PowerConsumption_Zone2 + PowerConsumption_Zone3)
head(powerconsumption, 6)
```

```{r}
avg_daily <- powerconsumption %>%
  mutate(date = as.Date(Datetime)) %>%
  group_by(date) %>%
  summarize(avg_daily_consumption = mean(total_consumption))

ggplot(data=avg_daily, aes(x=date, y=avg_daily_consumption, group=1)) +
  geom_line(color="darkgreen") + 
  labs(title = "Avg Daily Power Consumption", x = "Date", y = "Power Consumption", caption = "Fig. 1") +
  theme(plot.title = element_text(hjust = 0.5))
```

The average daily power consumption is characterized by an overall trend that peaks in the summer months and potentially a weekly seasonal trend. The data is not stationary and the variance seems to be constant disregarding the overall trend.

```{r}
corr_matrix <- powerconsumption %>%
  select(Temperature, Humidity, WindSpeed, DiffuseFlows, total_consumption)
ggcorrplot(cor(corr_matrix), type="lower") +
  labs(title = "Correlation Heatmap", caption = "Fig. 2")
```

The Temperature variable seems to be moderately correlated to Humidity, WindSpeed, and total_consumption

```{r}
hourly<- powerconsumption %>%
  mutate(hour = hour(Datetime))

ggplot(data = hourly, aes(x=hour, y=total_consumption, group=hour)) +
  geom_boxplot() +
  labs(title = "Hourly Power Consumption", x = "Hour", y = "Power Consumption", caption = "Fig. 3") + 
  theme(plot.title = element_text(hjust = 0.5))
```

There is potentially a seasonal trend across the hours of the day. Lowest consumption is around 6am and increases until about 8pm where it begins to decrease again. 

# Analysis Plan

In this project, our goal is to forecast the total power consumption in Tetouan, Morocco (across all three zones), using time series models while also exploring how extreme weather events and seasonal/daily patterns influence consumption trends. Our response variable will be “total consumption”, and we’ll use “temperature”, “humidity”, “wind speed”, and “diffuse flows” as our regressor variables.

Below are the key questions we aim to answer:

### 1. How accurately can we forecast the power consumption for the next 50 minutes using time series models, and which model performs the best?

To evaluate forecasting accuracy, we will implement a series of linear regression models and compare their performance using the Root Mean Squared Error (RMSE) metric. We plan to do some variable selection using AIC/BIC and introduce some dummy/lag variables to create the most optimal forecasting model. Some examples of models we plan to implement:

-   Using **time, temperature, humidity, wind speed, and a quarterly dummy variable**. Where time is measured at 10-minute intervals\
-   Using **time, temperature, humidity, wind speed, diffuse flows, and a quarterly dummy variable.** Where time is measured at 10-minute intervals

### 2. Which weather event (humidity, temperature, diffuse flows, wind speed) has the greatest influence on power consumption?

We are also interested in understanding which extreme weather conditions influence the consumption patterns the most. To explore this, we will:

-   Analyze the cross-correlation between the variables
-   Evaluate the absolute weight of the variables (if significant)
-   Examine the lagged variables on the weather events to understand whether past weather events affect present power consumption

### 3. Are there any seasonal or daily cycles in the power consumption?

Since we are more likely to consume energy in relation to the time of day or week, we want to analyze the daily/weekly/seasonal patterns in the power consumption. For this we will try to use spectral analysis to find any underlying cyclical patterns. However, spectral analysis usually requires that the time series data is stationary. As we can see in Figure 1, there is a clear upward trend during the summer months. We will use the differencing detrending method to make our data stationary in order to conduct our spectral analysis methods. Some methods we can try are:

       
* **Fast Fourier Transform:**  

  - Converts the time series into the frequency domain to identify dominant cycles in power consumption
  - Helps to determine if there are daily, weekly or seasonal trends  

* **Periodogram**   

  - Visualization of how power consumption varies with frequency. This method involves viewing the time series as a sum of cousin waves with varying amplitudes and frequencies.
  - Peaks in the periodogram indicate strong periodic components  

* **Wavelet Transform (optional additional analysis)**  

  - Similar to Fourier transform, but captures both frequency and time variations 
  - Useful for analyzing time-varying energy consumption trends  


By addressing these questions, we hope to gain deeper insights into power consumption forecasting, extreme weather effects, and seasonal patterns in Morocco's energy consumption.  

**References**  

BasicSpectralAnalysisExample. (n.d.). Retrieved March 27, 2025, from https://www.mathworks.com/help/matlab/math/basic-spectral-analysis.html  

6.1 The periodogram. (n.d.). PennState: Statistics Online Courses. Retrieved March 27, 2025, from https://online.stat.psu.edu/stat510/lesson/6/6.1  

Wavelet Transforms - An overview. (n.d.). ScienceDirect Topics. Retrieved March 27, 2025, from https://www.sciencedirect.com/topics/computer-science/wavelet-transforms

# Analysis

## Regression Model
```{r}
#powerconsumption is our main dataframe
power_ts <- as.ts(powerconsumption$total_consumption)
diff_power_ts <- diff(power_ts)
```

```{r}
tsplot(power_ts)
tsplot(diff_power_ts)
```

```{r}
time_consumption <- time(powerconsumption$total_consumption)

power.lm <- lm(total_consumption ~ time_consumption + Temperature + Humidity + WindSpeed + DiffuseFlows, data=powerconsumption)
summary(power.lm)

power.lm2 <- lm(total_consumption ~ time_consumption + time_consumption2 + Temperature + Humidity + WindSpeed + DiffuseFlows, data=powerconsumption)
summary(power.lm2)

power.lm3 <- lm(total_consumption ~ poly(time_consumption, 11, raw=TRUE) + Temperature + Humidity + WindSpeed + DiffuseFlows, data=powerconsumption)
summary(power.lm3)


```

```{r}
hourly.lm <- lm(total_consumption ~ poly(time_consumption, 11, raw=TRUE) + Temperature + Humidity + WindSpeed + DiffuseFlows + factor(hour), data=hourly)
summary(hourly.lm)
par(mfrow=c(2,2))
plot(hourly.lm)
Box.test(resid(hourly.lm), lag = 10, type = "Ljung-Box")
```
Even in our best efforts to model the dataset using a linear model, our residuals are highly correlated based on the Ljung-Box test. Therefore, we will fit a dynamic SARIMA model with regressors. 




## SARIMA Model (Don't include time or hourly factor in xreg)


```{r}
diff_acf <- acf(diff_power_ts, lag.max = 500)
diff_pacf <- pacf(diff_power_ts, lag.max = 500)
which.max(diff_acf$acf)
#plot(diff_acf)
plot(diff_acf$acf,type='h')
abline(v=c(144,288,432),col='red')

acf2(diff(diff_power_ts,144),500)
```
```{r}
diff_seasonal_acf <- acf(diff(diff_power_ts, 144), lag.max=500)
```

```{r}
# lm model on hourly data
hourly.lm <- lm(total_consumption ~ time(total_consumption) + Temperature + Humidity + WindSpeed + DiffuseFlows + factor(hour), data=hourly)
summary(hourly.lm)
par(mfrow= c(2,2))
plot(hourly.lm)
acf2(resid(hourly.lm),500)
```


```{r}
# lm model on hourly data (without factor(hour))
hourly.lm2 <- lm(total_consumption ~ time(total_consumption) + Temperature + Humidity + WindSpeed + DiffuseFlows, data=hourly)
summary(hourly.lm2)
par(mfrow= c(2,2))
plot(hourly.lm2)

tsplot(resid(hourly.lm2))
acf2(resid(hourly.lm2),500)

r2=resid(hourly.lm2)
acf2(diff(r2,144),500)
acf2(diff(r2),500)
acf2(diff(diff(r2,144)),500)
```


```{r}

Box.test(resid(hourly.lm), lag = 10, type = "Ljung-Box")

```

#Spectral Analysis

```{r}
ts_data <- ts(powerconsumption)
detrended <- ts_data - mean(ts_data, na.rm = TRUE)
# Optional: Remove linear trend
detrended <- detrended - predict(lm(detrended ~ time(detrended)))

fft_result <- fft(detrended)
n <- length(fft_result)

# Frequencies (in cycles/hour)
sampling_rate <- 6  # 6 samples per hour (10-minute intervals)
freq <- (0:(n-1)) * (sampling_rate / n)  # Convert to cycles/hour

# Periods (in hours)
periods <- 1 / freq  # e.g., 24 = daily cycle

power <- Mod(fft_result)^2 / n  # Squared magnitude = power

# Plot up to Nyquist frequency (3 cycles/hour for 10-minute data)
nyquist <- sampling_rate / 2
keep <- freq <= nyquist & freq > 0  # Ignore 0-frequency (DC component)

ggplot(data.frame(freq = freq[keep], power = power[keep]), aes(freq, power)) +
  geom_line() +
  geom_vline(xintercept = c(1, 1/24), color = "red", linetype = "dashed") +  # Hourly/daily
  labs(title = "FFT Power Spectrum",
       x = "Frequency (cycles/hour)",
       y = "Power") +
  scale_x_continuous(breaks = c(1/24, 1, 2, 3), labels = c("Daily (1/24)", "Hourly (1)", "2", "3")) +
  theme_minimal()
```
##normalized spectral 

```{r}
# After your existing code...
power_norm <- power[keep] / max(power[keep])  # 0-1 scaling
power_db <- 10 * log10(power[keep] / max(power[keep]))  # Decibel scale

# Update your ggplot with normalized values
ggplot(data.frame(freq = freq[keep], power = power_db), aes(freq, power)) +
  geom_line() +
  geom_vline(xintercept = c(1, 1/24), color = "red", linetype = "dashed") +
  labs(title = "Normalized FFT Power Spectrum (dB)",
       x = "Frequency (cycles/hour)",
       y = "Power (dB)") +
  scale_x_continuous(breaks = c(1/24, 1, 2, 3), 
                   labels = c("Daily (1/24)", "Hourly (1)", "2", "3")) +
  theme_minimal()

```

```{r}
# 0. Apply Hann window to reduce spectral leakage
library(signal)
hann_window <- hanning(length(detrended))  
# hann_window <- flattopwin(length(detrended))  
detrended_windowed <- detrended * hann_window

# 1. Compute FFT with windowed data
fft_result <- fft(detrended_windowed)
n <- length(fft_result)

# 2. Calculate frequencies and power
sampling_rate <- 6  # 6 samples per hour
freq <- (0:(n-1)) * (sampling_rate / n)
power <- Mod(fft_result)^2 / n

# 3. Filter to Nyquist frequency
nyquist <- sampling_rate / 2
keep <- freq <= nyquist & freq > 0

# 4. Normalize and calculate metrics
power_norm <- power[keep] / max(power[keep])  # 0-1 scaling
power_db <- 10 * log10(power_norm)            # Decibel scale
power_rel <- 100 * power[keep]/sum(power[keep]) # Relative power %

# 5. Identify significant peaks (SNR > 10)
noise_floor <- median(power[keep])
significant_peaks <- which(power[keep] > 10 * noise_floor)

# 6. Create enhanced plot
library(ggplot2)
ggplot(data.frame(freq = freq[keep], 
                 power_db = power_db,
                 power_rel = power_rel,
                 is_peak = seq_along(power[keep]) %in% significant_peaks), 
       aes(x = freq)) +
  
  # Main spectrum line
  geom_line(aes(y = power_db), color = "black") +
  
  # Highlight significant peaks
  geom_point(data = ~ subset(., is_peak), 
            aes(y = power_db), color = "blue", size = 2) +
  
  # Reference lines and labels
  geom_vline(xintercept = c(1/24, 0.66), color = "red", linetype = "dashed") +
  
  # Dual axis for dB and relative power
  scale_y_continuous(
    name = "Power (dB)",
    sec.axis = sec_axis(~ . * 0.1, name = "Relative Power (%)")
  ) +
  
  # Frequency labels
  scale_x_continuous(
    breaks = c(1/24, 0.66, 1, 2, 3),
    labels = c("Daily (1/24)","0.66", "Hourly (1)", "2", "3"),
    limits = c(0, 3)
  ) +
  
  labs(title = "Enhanced FFT Power Spectrum with Significant Peaks",
       x = "Frequency (cycles/hour)") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
This graph, processed with a flat-top window, reveals a more uniform distribution of peaks across frequencies (1.4, 2, and 2.6 cycles/hour) compared to the Hann window’s results. This occurs because the flat-top window prioritizes amplitude accuracy over frequency resolution, preserving the true power of all components—even weaker ones—while broadening their appearance. The blue dots highlight statistically significant peaks (SNR > 5), indicating meaningful cycles like the dominant daily rhythm (1/24 cycles/hour) and unexpected sub-hourly patterns (e.g., 43-minute cycles at 1.4 cycles/hour). The decibel (dB) scale (logarithmic) compresses the dynamic range, making both strong and weak peaks visible; for example, a −50 dB peak is 100,000× weaker than the maximum (0 dB). The flat-top window’s output suggests these sub-hourly peaks may reflect real operational patterns (e.g., equipment cycling every 30–43 minutes) rather than noise, but cross-validation with time-domain filtering or equipment logs is recommended. This analysis balances sensitivity (flat-top) and clarity (Hann) to uncover hidden energy dynamics.

```{r}
target_freq <- 0.8
idx <- which.min(abs(freq[keep] - target_freq))  # Find nearest frequency bin
snr <- power[keep][idx] / median(power[keep])    # SNR = Peak / Median noise

snr

exact_freq <- freq[keep][which.max(power[keep])]  # Find strongest peak
exact_period <- 1 / exact_freq                   # Exact period in hours
exact_period
```
SNR > 3 means it is likely a real signal, cycle every 1.5 hours

```{r}
library(astsa)
spectrum(diff_power_ts)
```

##periodogram
```{r}
# Base R periodogram (unsmoothed)
spec <- spectrum(detrended_windowed, 
                 log = "no",     # linear scale
                 plot = TRUE,    # plot the result
                 spans = NULL,   # no smoothing
                 taper = 0)      # already windowed

# Convert frequencies to cycles/hour (already scaled if sampling_rate = 1)
freqs <- spec$freq * sampling_rate  # rescale to match your FFT units
power <- spec$spec

```

```{r}
# Assume 'spec' is the output from the spectrum() function
# The result of spectrum() has components: spec$freq (frequencies) and spec$spec (power values)

# Extract the frequency and power values
frequencies <- spec$freq
power_values <- spec$spec

# Find the peak's magnitude
peak_magnitude <- max(power_values)

# Identify the baseline (average noise level)
# You can define the baseline as the average power in a range where no peaks are present
# For example, we can take the last 20% of the power spectrum as a baseline noise region
baseline_noise_range <- power_values[round(length(power_values) * 0.8):length(power_values)]
baseline_magnitude <- mean(baseline_noise_range)

# Calculate the ratio of the peak magnitude to the baseline noise level
ratio <- peak_magnitude / baseline_magnitude

# Print the results
cat("Peak Magnitude:", peak_magnitude, "\n")
cat("Baseline Magnitude:", baseline_magnitude, "\n")
cat("Peak-to-Baseline Ratio:", ratio, "\n")
```

We see that the peak magnitude is much larger than the baseline magnitude and that means that the sole peak is definitely significant. 

